# -*- coding: utf-8 -*-
"""aiml1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1KW1D74TE6RSDhQsuK_YgnNFr17p4MCjM
"""

import tensorflow as tf
print("Num GPUs Available: ", len(tf.config.list_physical_devices('GPU')))

from google.colab import drive
drive.mount('/content/drive')

from google.colab import drive
import os  # Import the os module

# Mount Google Drive
drive.mount('/content/drive')

# Unzip the dataset
!unzip -qn /content/drive/MyDrive/final_dataset.zip -d /content/subset

# List the contents of the folder
print("Files in dataset folder:", os.listdir("/content/subset"))

import os
import cv2
import numpy as np
from glob import glob
import matplotlib.pyplot as plt
import shutil
import warnings
import pandas as pd
import time
import random
import tensorflow as tf

!pip install opencv-python matplotlib tensorflow pandas

LOCAL_DATASET_PATH = "subset"
if os.path.exists(LOCAL_DATASET_PATH):
    shutil.rmtree(LOCAL_DATASET_PATH)

SUBSET_PATH = "/content/drive/MyDrive/final_dataset.zip"  # Update with the actual path
os.system(f"unzip -qn {SUBSET_PATH} -d {LOCAL_DATASET_PATH} > /dev/null")

for folder in glob(LOCAL_DATASET_PATH + "/*"):
    for in_folder in glob(folder + "/*"):
        file_name = in_folder.split("/")[-1]
        shutil.move(in_folder, os.path.join(LOCAL_DATASET_PATH, file_name))
    shutil.rmtree(folder)

dataset = pd.read_csv(os.path.join(LOCAL_DATASET_PATH, "dataset.csv"), index_col=[0])
print("Dataset loaded successfully!")

dataset = pd.read_csv(os.path.join(LOCAL_DATASET_PATH, "/content/subset/dataset.csv"))

dataset

def create_unet_model(input_size=(512, 512, 1)):
    inputs = tf.keras.layers.Input(input_size)
    # Encoding
    c1 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', padding='same')(inputs)
    p1 = tf.keras.layers.MaxPooling2D((2, 2))(c1)
    c2 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same')(p1)
    p2 = tf.keras.layers.MaxPooling2D((2, 2))(c2)

    # Bottleneck
    c3 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same')(p2)

    # Decoding
    u1 = tf.keras.layers.Conv2DTranspose(32, (3, 3), strides=(2, 2), padding='same')(c3)
    c4 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same')(u1)
    u2 = tf.keras.layers.Conv2DTranspose(16, (3, 3), strides=(2, 2), padding='same')(c4)
    c5 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', padding='same')(u2)

    outputs = tf.keras.layers.Conv2D(1, (1, 1), activation='sigmoid')(c5)

    model = tf.keras.models.Model(inputs, outputs)
    return model

# Create and compile the model
unet = create_unet_model()
unet.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
print("U-Net model created!")

# Save the model for future use
unet.save("/content/unet_model.h5")
print("Model saved as /content/unet_model.h5")

def obtain_subset(dataset):
    images = [os.path.join(LOCAL_DATASET_PATH, image) for image in dataset["preprocessed_image"].values]
    masks = [os.path.join(LOCAL_DATASET_PATH, image) for image in dataset["mask"].values]
    x_centers = [int(x) for x in dataset["acf_center_x"].values]
    y_centers = [int(y) for y in dataset["acf_center_y"].values]
    angles = [int(angle) for angle in dataset["arm_angle"].values]
    ids = [int(id) for id in dataset.index]

    # Normalize angles and avoid similarity between 0 and 180
    for idx, angle in enumerate(angles):
        if angle > 170:
            angles[idx] = 0

    return images, masks, x_centers, y_centers, angles, ids

# Define obtain_subset
def obtain_subset(dataset):
    images = [os.path.join(LOCAL_DATASET_PATH, image) for image in dataset["preprocessed_image"].values]
    masks = [os.path.join(LOCAL_DATASET_PATH, image) for image in dataset["mask"].values]
    x_centers = [int(x) for x in dataset["acf_center_x"].values]
    y_centers = [int(y) for y in dataset["acf_center_y"].values]
    angles = [int(angle) for angle in dataset["arm_angle"].values]
    ids = [int(id) for id in dataset.index]

    # Normalize angles and avoid similarity between 0 and 180
    for idx, angle in enumerate(angles):
        if angle > 170:
            angles[idx] = 0

    return images, masks, x_centers, y_centers, angles, ids

# Dataset splitting
NUM_TRAIN_SAMPLES = int(len(dataset) * 0.70)
NUM_VAL_SAMPLES = int(len(dataset) * 0.20)
NUM_TEST_SAMPLES = len(dataset) - NUM_TRAIN_SAMPLES - NUM_VAL_SAMPLES

train_images, train_masks, train_acf_x_centers, train_acf_y_centers, train_angles, train_ids = obtain_subset(dataset[:NUM_TRAIN_SAMPLES])
val_images, val_masks, val_acf_x_centers, val_acf_y_centers, val_angles, val_ids = obtain_subset(dataset[NUM_TRAIN_SAMPLES:NUM_TRAIN_SAMPLES + NUM_VAL_SAMPLES])
test_images, test_masks, test_acf_x_centers, test_acf_y_centers, test_angles, test_ids = obtain_subset(dataset[NUM_VAL_SAMPLES + NUM_TRAIN_SAMPLES:])

print("Dataset split successfully!")

# Define preprocessing functions
def preprocess_image(image_path):
    image = tf.io.read_file(image_path)
    image = tf.image.decode_png(image, channels=1)
    image = tf.image.resize(image, [512, 512])
    image = tf.cast(image, tf.float32) / 255.0  # Normalize to [0, 1]
    return image

def preprocess_mask(mask_path):
    mask = tf.io.read_file(mask_path)
    mask = tf.image.decode_png(mask, channels=1)
    mask = tf.image.resize(mask, [512, 512])
    mask = tf.cast(mask, tf.float32) / 255.0  # Normalize to [0, 1]
    return mask

# Create TensorFlow datasets
train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_masks))
train_dataset = train_dataset.map(lambda x, y: (preprocess_image(x), preprocess_mask(y)))
train_dataset = train_dataset.batch(16).shuffle(buffer_size=100).prefetch(buffer_size=tf.data.AUTOTUNE)

val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_masks))
val_dataset = val_dataset.map(lambda x, y: (preprocess_image(x), preprocess_mask(y)))
val_dataset = val_dataset.batch(16).prefetch(buffer_size=tf.data.AUTOTUNE)

def create_unet_model(input_size=(512, 512, 1)):
    inputs = tf.keras.layers.Input(input_size)
    # Encoding
    c1 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', padding='same')(inputs)
    p1 = tf.keras.layers.MaxPooling2D((2, 2))(c1)
    c2 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same')(p1)
    p2 = tf.keras.layers.MaxPooling2D((2, 2))(c2)

    # Bottleneck
    c3 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same')(p2)

    # Decoding
    u1 = tf.keras.layers.Conv2DTranspose(32, (3, 3), strides=(2, 2), padding='same')(c3)
    c4 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same')(u1)
    u2 = tf.keras.layers.Conv2DTranspose(16, (3, 3), strides=(2, 2), padding='same')(c4)
    c5 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', padding='same')(u2)

    outputs = tf.keras.layers.Conv2D(1, (1, 1), activation='sigmoid')(c5)

    model = tf.keras.models.Model(inputs, outputs)
    return model

# Create and compile the model
unet = create_unet_model()
unet.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
print("Model created and compiled!")

# Train the model
history = unet.fit(
    train_dataset,
    validation_data=val_dataset,
    epochs=10
)

# Example: Plotting loss and accuracy
import matplotlib.pyplot as plt

# Assuming you have `history` from model.fit()
plt.figure(figsize=(12, 4))

# Loss
plt.subplot(1, 2, 1)
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Loss over Epochs')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()

# Accuracy
plt.subplot(1, 2, 2)
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.title('Accuracy over Epochs')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()

plt.show()

unet.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])

def augment(image, mask):
    image = tf.image.random_flip_left_right(image)
    mask = tf.image.random_flip_left_right(mask)
    return image, mask

train_dataset = train_dataset.map(augment).shuffle(buffer_size=100).batch(16).prefetch(tf.data.AUTOTUNE)

converter = tf.lite.TFLiteConverter.from_keras_model(unet)
tflite_model = converter.convert()
with open("unet_model.tflite", "wb") as f:
    f.write(tflite_model)
print("Model converted to TensorFlow Lite format!")

def preprocess_image(image_path):
    image = tf.io.read_file(image_path)
    image = tf.image.decode_png(image, channels=1)
    image = tf.image.resize(image, [512, 512])
    image = tf.cast(image, tf.float32) / 255.0  # Normalize to [0, 1]
    return image

# Preprocess all test images
preprocessed_test_images = [preprocess_image(img) for img in test_images]
preprocessed_test_images = tf.stack(preprocessed_test_images)  # Stack into a tensor

def preprocess_mask(mask_path):
    mask = tf.io.read_file(mask_path)
    mask = tf.image.decode_png(mask, channels=1)
    mask = tf.image.resize(mask, [512, 512])
    mask = tf.cast(mask, tf.float32) / 255.0  # Normalize to [0, 1]
    return mask

preprocessed_test_masks = [preprocess_mask(mask) for mask in test_masks]
preprocessed_test_masks = tf.stack(preprocessed_test_masks)  # Stack into a tensor

def smoothed_iou_metric(y_true, y_pred, smooth=1e-6):
    # Ensure masks are binary
    y_true = tf.cast(y_true > 0.5, tf.float32)
    y_pred = tf.cast(y_pred > 0.5, tf.float32)

    intersection = tf.reduce_sum(y_true * y_pred)
    union = tf.reduce_sum(y_true + y_pred) - intersection
    iou = (intersection + smooth) / (union + smooth)
    return iou

# Predict on preprocessed test images
predictions = unet.predict(preprocessed_test_images)

# Threshold predictions to create binary masks
binary_predictions = tf.cast(predictions > 0.5, tf.float32)

# Compute IoU for each sample
ious = [
    smoothed_iou_metric(preprocessed_test_masks[i], binary_predictions[i])
    for i in range(len(preprocessed_test_images))
]
mean_iou = tf.reduce_mean(ious)

print(f"Mean IoU on test dataset: {mean_iou.numpy()}")

print(preprocessed_test_images.shape)
print(preprocessed_test_masks.shape)
print(predictions.shape)

for i, iou in enumerate(ious):
    print(f"Sample {i+1}: IoU = {iou.numpy():.4f}")
print(f"Overall Mean IoU: {mean_iou.numpy():.4f}")

import matplotlib.pyplot as plt

def visualize_sample(image, true_mask, pred_mask, sample_index):
    plt.figure(figsize=(12, 6))

    # Display the original image
    plt.subplot(1, 3, 1)
    plt.title(f"Test Image {sample_index}")
    plt.imshow(tf.squeeze(image), cmap='gray')
    plt.axis('off')

    # Display the ground truth mask
    plt.subplot(1, 3, 2)
    plt.title(f"Predicted Mask {sample_index}")
    plt.imshow(tf.squeeze(true_mask), cmap='gray')
    plt.axis('off')


# Visualize a few samples
for i in range(5):  # Visualize the first 5 samples
    visualize_sample(preprocessed_test_images[i], preprocessed_test_masks[i], binary_predictions[i], i+1)

import os

# Create a directory to save predictions
os.makedirs('/content/predictions', exist_ok=True)

# Save the predicted masks as images
for i, pred in enumerate(binary_predictions):
    pred_image = tf.squeeze(pred).numpy() * 255.0  # Convert to [0, 255] range
    cv2.imwrite(f"/content/predictions/prediction_{i+1}.png", pred_image)
print("Predictions saved to /content/predictions/")

# Find and display the worst-performing sample
min_iou_index = tf.argmin(ious).numpy()
print(f"Worst-performing sample index: {min_iou_index}, IoU: {ious[min_iou_index].numpy():.4f}")
visualize_sample(preprocessed_test_images[min_iou_index], preprocessed_test_masks[min_iou_index], binary_predictions[min_iou_index], min_iou_index+1)

IMAGE_SIZE = 512
BATCH_SIZE = 16

TOTAL_SAMPLES = len(dataset)
print("Total samples:", TOTAL_SAMPLES)

NUM_TRAIN_SAMPLES = int(TOTAL_SAMPLES * 0.70)
NUM_VAL_SAMPLES = int(TOTAL_SAMPLES * 0.20)
NUM_TEST_SAMPLES = int(TOTAL_SAMPLES * 0.10)

print("Number of train images:",NUM_TRAIN_SAMPLES," val images:",NUM_VAL_SAMPLES," test images:",NUM_TEST_SAMPLES)

def obtain_subset(dataset):
  images = [os.path.join(LOCAL_DATASET_PATH, image) for image in dataset["preprocessed_image"].values]
  masks = [os.path.join(LOCAL_DATASET_PATH, image) for image in dataset["mask"].values]
  x_centers = [ int(x) for x in dataset["acf_center_x"].values]
  y_centers = [ int(y) for y in dataset["acf_center_y"].values]
  angles = [ int(angle) for angle in dataset["arm_angle"].values]
  ids = [ int(id) for id in dataset.index]

  # Normalize angles and avoid similarity between 0 and 180
  for idx, angle in enumerate(angles):
    if angle > 170:
      angles[idx] = 0

  return images, masks, x_centers, y_centers, angles, ids

train_images, train_masks, train_acf_x_centers, train_acf_y_centers, train_angles, train_ids = obtain_subset(dataset[:NUM_TRAIN_SAMPLES])
val_images, val_masks, val_acf_x_centers, val_acf_y_centers, val_angles, val_ids = obtain_subset(dataset[NUM_TRAIN_SAMPLES : NUM_VAL_SAMPLES + NUM_TRAIN_SAMPLES])
test_images, test_masks, test_acf_x_centers, test_acf_y_centers, test_angles, test_ids = obtain_subset(dataset[NUM_VAL_SAMPLES + NUM_TRAIN_SAMPLES : ])

# Save the model for future use
unet.save("/content/unet_model.h5")
print("Model saved as /content/unet_model.h5")

for idx, sample in dataset.iterrows():
  if not os.path.exists(os.path.join(LOCAL_DATASET_PATH, sample["preprocessed_image"])):
    print(os.path.exists(os.path.joinLOCAL_DATASET_PATH, sample["preprocessed_image"]), "doesn't exist!")
  if not os.path.exists(os.path.join(LOCAL_DATASET_PATH, sample["mask"])):
    print(os.path.exists(os.path.joinLOCAL_DATASET_PATH, sample["mask"]), "doesn't exist!")
  if not os.path.exists(os.path.join(LOCAL_DATASET_PATH, sample["nir_image"])):
    print(os.path.exists(os.path.joinLOCAL_DATASET_PATH, sample["nir_image"]), "doesn't exist!")

print("Dataset size:",len(dataset))
print("Masks",len(glob("/content/subset/masks/*.png")))
print("Preprocessed images",len(glob("/content/subset/preprocessed_images/*.png")))
print("NIR images",len(glob("/content/subset/nir_images/*.png")))

IMAGE_SIZE = 512
BATCH_SIZE = 16
NUM_CLASSES = 3
MULTITASK = True

TOTAL_SAMPLES = len(dataset)
print("Total samples:", TOTAL_SAMPLES)

NUM_TRAIN_SAMPLES = int(TOTAL_SAMPLES * 0.70)
NUM_VAL_SAMPLES = int(TOTAL_SAMPLES * 0.20)
NUM_TEST_SAMPLES = int(TOTAL_SAMPLES * 0.10)

print("Number of train images:",NUM_TRAIN_SAMPLES," val images:",NUM_VAL_SAMPLES," test images:",NUM_TEST_SAMPLES)

def obtain_subset(dataset):
  images = [os.path.join(LOCAL_DATASET_PATH, image) for image in dataset["preprocessed_image"].values]
  masks = [os.path.join(LOCAL_DATASET_PATH, image) for image in dataset["mask"].values]
  x_centers = [ int(x) for x in dataset["acf_center_x"].values]
  y_centers = [ int(y) for y in dataset["acf_center_y"].values]
  angles = [ int(angle) for angle in dataset["arm_angle"].values]
  if MULTITASK:
    return images, masks, x_centers, y_centers, angles
  else:
    return images, masks

def read_image(image_path, mask=False):
  image = tf.io.read_file(image_path)
  if mask:
    image = tf.image.decode_png(image, channels=1)
    image.set_shape([None, None, 1])
    image = tf.image.resize(images=image, size=[IMAGE_SIZE, IMAGE_SIZE])
    image = tf.cast(image, dtype=tf.int32, name = 'mask')
  else:
    image = tf.image.decode_png(image, channels=1)
    image.set_shape([None, None, 1])
    image = tf.image.resize(images=image, size=[IMAGE_SIZE, IMAGE_SIZE], name="image")
    image = image / 127.5 - 1
  return image

# Data loaders for normal image segmentation
def load_data(image_list, mask_list):
    image = read_image(image_list)
    mask = read_image(mask_list, mask=True)
    return image, mask

def data_generator(image_list, mask_list):
    dataset = tf.data.Dataset.from_tensor_slices((image_list, mask_list))
    dataset = dataset.map(load_data, num_parallel_calls=tf.data.AUTOTUNE)
    dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)
    return dataset

# Data loaders for multitask
def load_data_multitask(image, mask, x, y, angle):
  image = read_image(image)
  mask = read_image(mask, mask=True)
  x = x/IMAGE_SIZE
  y = y/IMAGE_SIZE
  values = tf.convert_to_tensor([x, y], dtype=tf.float32, name="values")
  return image, mask, values

def data_generator_multitask(images, masks, acf_x_centers, acf_y_centers, angles):
  dataset = tf.data.Dataset.from_tensor_slices((images, masks, acf_x_centers, acf_y_centers, angles))
  dataset = dataset.map(load_data_multitask, num_parallel_calls=tf.data.AUTOTUNE)
  dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)
  return dataset

if MULTITASK:
  train_images, train_masks, train_acf_x_centers, train_acf_y_centers, train_angles = obtain_subset(dataset[:NUM_TRAIN_SAMPLES])
  val_images, val_masks, val_acf_x_centers, val_acf_y_centers, val_angles = obtain_subset(dataset[NUM_TRAIN_SAMPLES : NUM_VAL_SAMPLES + NUM_TRAIN_SAMPLES])
  test_images, test_masks, test_acf_x_centers, test_acf_y_centers, test_angles = obtain_subset(dataset[NUM_VAL_SAMPLES + NUM_TRAIN_SAMPLES : ])

  train_dataset = data_generator_multitask(train_images, train_masks, train_acf_x_centers, train_acf_y_centers, train_angles)
  val_dataset = data_generator_multitask(val_images, val_masks, val_acf_x_centers, val_acf_y_centers, val_angles)
  test_dataset = data_generator_multitask(test_images, test_masks, test_acf_x_centers, test_acf_y_centers, test_angles)
else:
  train_images, train_masks = obtain_subset(dataset[:NUM_TRAIN_SAMPLES])
  val_images, val_masks = obtain_subset(dataset[NUM_TRAIN_SAMPLES : NUM_VAL_SAMPLES + NUM_TRAIN_SAMPLES])
  test_images, test_masks = obtain_subset(dataset[NUM_VAL_SAMPLES + NUM_TRAIN_SAMPLES : ])

  train_dataset = data_generator(train_images, train_masks)
  val_dataset = data_generator(val_images, val_masks)
  test_dataset = data_generator(test_images, test_masks)

print("Train subset has n batches:", len(train_dataset), "- Data type:", train_dataset)
print("Val subset has n batches:", len(val_dataset), "- Data type:", val_dataset)
print("Test subset has n batches:", len(test_dataset), "- Data type:", test_dataset)

def show_random_sample(subset):

  random_batch = random.randint(0, len(subset))
  for idx, batch in enumerate(subset):
    if idx == random_batch:
      images = batch[0]
      masks = batch[1]
      values = batch[2]

      random_sample = random.randint(0, len(images)-1)
      image = np.squeeze(images[random_sample].numpy())
      mask = np.squeeze(masks[random_sample].numpy())
      x = int(values[random_sample].numpy()[0]*IMAGE_SIZE)
      y = int(values[random_sample].numpy()[1]*IMAGE_SIZE)
      # angle = int(values[random_sample].numpy()[2])

      image = cv2.circle(image, (x,y), radius=5, color=4, thickness=-1)
      # print("Angle:",angle)

      fif = plt.figure()
      fif.add_subplot(1,2, 1)
      plt.imshow(image, cmap="gray")
      fif.add_subplot(1,2, 2)
      plt.imshow(mask, cmap="gray")
      plt.show(block=True)
      break

show_random_sample(train_dataset)

import os
import time
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np

# Custom Model Class
class CustomModel(tf.keras.Model):
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.avg_loss_training = tf.keras.metrics.Mean('train_loss', dtype=tf.float32)
        self.avg_loss_validation = tf.keras.metrics.Mean('val_loss', dtype=tf.float32)

    def train_step(self, data):
        images, masks, values = data
        with tf.GradientTape() as tape:
            outputs = self(images, training=True)  # forward pass
            # segmentation loss
            crossentropy_loss = tf.keras.losses.sparse_categorical_crossentropy(masks, outputs[0])
            # regression loss
            mse_loss = tf.keras.losses.MeanSquaredError()
            regression_loss = tf.reduce_sum(mse_loss(values, outputs[1]))
            total_loss = crossentropy_loss + regression_loss

        # Compute gradients
        gradients = tape.gradient(total_loss, self.trainable_variables)
        # Update weights
        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))
        # Update metrics (includes the metric that tracks the loss)
        self.avg_loss_training.update_state(total_loss)
        return {"train_loss": self.avg_loss_training.result()}

    def test_step(self, data):
        images, masks, values = data
        outputs = self(images, training=False)
        # segmentation loss
        crossentropy_loss = tf.keras.losses.sparse_categorical_crossentropy(masks, outputs[0])
        # regression loss
        mse_loss = tf.keras.losses.MeanSquaredError()
        regression_loss = tf.reduce_sum(mse_loss(values, outputs[1]))
        total_loss = crossentropy_loss + regression_loss
        # Update metrics
        self.avg_loss_validation.update_state(total_loss)
        return {"val_loss": self.avg_loss_validation.result()}

    @property
    def metrics(self):
        # List the metrics to reset their states at the start of each epoch
        return [self.avg_loss_training, self.avg_loss_validation]

# Define U-Net Model
def define_unet(img_size, num_classes, multitask=False):
    inputs = keras.Input(shape=img_size + (1,))

    # Downsampling
    x = layers.Conv2D(32, 3, strides=2, padding="same")(inputs)
    x = layers.BatchNormalization()(x)
    x = layers.Activation("relu")(x)

    previous_block_activation = x  # Set aside residual
    embeddings = None

    # Downsampling Blocks
    for filters in [64, 128, 256, 512]:
        x = layers.Activation("relu")(x)
        x = layers.SeparableConv2D(filters, 3, padding="same")(x)
        x = layers.BatchNormalization()(x)
        x = layers.Activation("relu")(x)
        x = layers.SeparableConv2D(filters, 3, padding="same")(x)
        x = layers.BatchNormalization()(x)
        x = layers.MaxPooling2D(3, strides=2, padding="same")(x)

        # Project residual
        residual = layers.Conv2D(filters, 1, strides=2, padding="same")(previous_block_activation)
        x = layers.add([x, residual])  # Add back residual
        previous_block_activation = x

        if filters == 512:
            embeddings = x

    # Upsampling
    for filters in [512, 256, 128, 64, 32]:
        x = layers.Activation("relu")(x)
        x = layers.Conv2DTranspose(filters, 3, padding="same")(x)
        x = layers.BatchNormalization()(x)
        x = layers.Activation("relu")(x)
        x = layers.Conv2DTranspose(filters, 3, padding="same")(x)
        x = layers.BatchNormalization()(x)
        x = layers.UpSampling2D(2)(x)

        # Project residual
        residual = layers.UpSampling2D(2)(previous_block_activation)
        residual = layers.Conv2D(filters, 1, padding="same")(residual)
        x = layers.add([x, residual])
        previous_block_activation = x

    # Regression Branch
    y = layers.Flatten()(embeddings)
    y = layers.Dense(128, activation='sigmoid')(y)
    y = layers.Dense(128, activation='sigmoid')(y)
    y = layers.Dense(64, activation='sigmoid')(y)
    output_regression = layers.Dense(2, activation='sigmoid', name='task_2_output')(y)

    # Segmentation Branch
    output_segmentation = layers.Conv2D(num_classes, 3, activation="softmax", padding="same", name='task_1_output')(x)

    # Define the model
    if multitask:
        model = CustomModel(inputs, outputs=[output_segmentation, output_regression])
    else:
        model = keras.Model(inputs, output_segmentation)
    return model

# Clear previous session and define U-Net
keras.backend.clear_session()
IMAGE_SIZE = (512, 512)
NUM_CLASSES = 3  # Adjust based on the number of classes in your segmentation task
MULTITASK = True  # Set to False if multitask is not required

unet = define_unet(IMAGE_SIZE, NUM_CLASSES, multitask=MULTITASK)

# Training Configuration
EPOCHS = 20
if MULTITASK:
    optimizer = keras.optimizers.Adam(learning_rate=0.01)
    unet.compile(optimizer=optimizer)

    # Train the model
    start = time.time()
    history = unet.fit(train_dataset,
                       validation_data=val_dataset,
                       epochs=EPOCHS,
                       verbose=1)
    print(f'Training time: {time.time() - start}\n')
else:
    unet.compile(optimizer="rmsprop",
                 loss="sparse_categorical_crossentropy",
                 metrics=['accuracy'])
    history = unet.fit(train_dataset, epochs=EPOCHS, validation_data=val_dataset, verbose=1)

# Save the trained model
unet.save("/content/unet_multitask.h5")
print("Model saved to /content/unet_multitask.h5")

import tensorflow as tf
import numpy as np
import cv2
import matplotlib.pyplot as plt
import random

# Constants
IMAGE_SIZE = 512  # Adjust as per your model's input size

# Preprocessing Functions
def read_image(image_path, mask=False):
    """
    Reads and preprocesses an image.
    - If `mask` is True, returns the resized mask.
    - If `mask` is False, returns the resized and normalized image.
    """
    image = tf.io.read_file(image_path)
    image = tf.image.decode_png(image, channels=1)  # Ensure grayscale image
    if mask:
        image = tf.image.resize(image, [IMAGE_SIZE, IMAGE_SIZE])  # Ensure size is [height, width]
        image = tf.cast(image, dtype=tf.int32)
        return image
    else:
        image = tf.image.resize(image, [IMAGE_SIZE, IMAGE_SIZE])  # Ensure size is [height, width]
        image = tf.cast(image, dtype=tf.float32) / 127.5 - 1  # Normalize to [-1, 1]
        return image

def normalize(image):
    """
    Crops and resizes the image to a fixed size.
    - `image`: TensorFlow tensor of the image.
    - Returns a resized tensor.
    """
    image = image[:, 540:1620]  # Example cropping (adjust as needed)
    image = tf.image.resize(images=image, size=[IMAGE_SIZE, IMAGE_SIZE])  # Resize to [height, width]
    return image

# Inference Function
def infer(model, image_tensor):
    """
    Performs inference using the model and an input image tensor.
    - `model`: Trained TensorFlow model.
    - `image_tensor`: Preprocessed input image (TensorFlow tensor).
    - Returns:
        - Predicted mask
        - Predicted x-coordinate
        - Predicted y-coordinate
    """
    # Ensure the input tensor has a batch dimension
    image_tensor = tf.expand_dims(image_tensor, axis=0)  # Shape: (1, 512, 512, 1)

    # Perform prediction
    mask, values = model.predict(image_tensor, verbose=0)

    # Process the mask
    mask = np.squeeze(mask)  # Remove batch dimension
    mask = np.argmax(mask, axis=2).astype(np.uint8)  # Convert probabilities to class indices

    # Process regression values
    values = np.squeeze(values)  # Remove batch dimension
    x = int(values[0] * IMAGE_SIZE)  # Scale x-coordinate to image size
    y = int(values[1] * IMAGE_SIZE)  # Scale y-coordinate to image size

    return mask, x, y

# Visualization Function
def show_prediction(image_file, mask_file, x_center, y_center, angle, model):
    """
    Displays the real and predicted mask overlayed on the input image.
    - `image_file`: Path to the input image.
    - `mask_file`: Path to the corresponding ground-truth mask.
    - `x_center`, `y_center`: Ground-truth center coordinates.
    - `angle`: Ground-truth angle (optional, not used here).
    - `model`: Trained model for inference.
    """
    # Preprocess the image and mask
    image_tensor = read_image(image_file, mask=False)
    mask_tensor = read_image(mask_file, mask=True)

    # Convert tensors to numpy arrays for visualization
    image_npy = (image_tensor.numpy() + 1) * 127.5  # Convert back to [0, 255]
    image_npy = image_npy.squeeze()  # Remove channel dimension
    mask_npy = np.squeeze(mask_tensor.numpy()).astype(np.uint8)

    # Perform inference
    predicted_mask, predicted_x, predicted_y = infer(model=model, image_tensor=image_tensor)

    # Overlay the center points on the masks
    mask_npy = cv2.circle(mask_npy, (x_center, y_center), radius=5, color=4, thickness=-1)
    predicted_mask = cv2.circle(predicted_mask, (predicted_x, predicted_y), radius=5, color=4, thickness=-1)

    # Plot the real and predicted masks
    plt.figure(figsize=(10, 5))
    plt.subplot(1, 2, 1)
    plt.title("Predicted")
    plt.imshow(image_npy, cmap="gray")
    plt.imshow(mask_npy, cmap="winter", alpha=0.5)
    plt.subplot(1, 2, 2)
    plt.title("Real")
    plt.imshow(image_npy, cmap="gray")
    plt.imshow(predicted_mask, cmap="winter", alpha=0.5)
    plt.show()

# Example Usage
# Replace the below variables with actual data from your dataset
random_sample = random.randint(0, len(test_images) - 1)  # Replace `test_images` with your test image paths
image = test_images[random_sample]
mask = test_masks[random_sample]
x_center = test_acf_x_centers[random_sample]
y_center = test_acf_y_centers[random_sample]
angle = test_angles[random_sample]

# Display prediction
show_prediction(image, mask, x_center, y_center, angle, unet)

import tensorflow as tf
import numpy as np
from tqdm import tqdm  # For progress bars
from sklearn.metrics import jaccard_score, accuracy_score, f1_score
from skimage.metrics import peak_signal_noise_ratio
from scipy.spatial import distance

# Constants
IMAGE_SIZE = 512  # Adjust based on your model's input size

# Preprocessing Functions
def read_image(image_path, mask=False):
    """
    Reads and preprocesses an image.
    - If `mask` is True, returns the resized mask.
    - If `mask` is False, returns the resized and normalized image.
    """
    image = tf.io.read_file(image_path)
    image = tf.image.decode_png(image, channels=1)  # Ensure grayscale image
    if mask:
        image = tf.image.resize(image, [IMAGE_SIZE, IMAGE_SIZE])  # Resize to [height, width]
        image = tf.cast(image, dtype=tf.int32)
        return image
    else:
        image = tf.image.resize(image, [IMAGE_SIZE, IMAGE_SIZE])  # Resize to [height, width]
        image = tf.cast(image, dtype=tf.float32) / 127.5 - 1  # Normalize to [-1, 1]
        return image

# Inference Function
def infer(model, image_tensor):
    """
    Performs inference using the model and an input image tensor.
    - `model`: Trained TensorFlow model.
    - `image_tensor`: Preprocessed input image (TensorFlow tensor).
    - Returns:
        - Predicted mask
    """
    predictions = model.predict(np.expand_dims((image_tensor), axis=0), verbose=0)
    predictions = np.squeeze(predictions[0])
    predictions = np.argmax(predictions, axis=2)
    return predictions

# Metrics Calculation Function
def find_metrics(images_list, masks_list, x_centers_list, y_centers_list, angles, model):
    """
    Computes metrics for a model according to the ground truth.
    - Metrics include IoU, Dice Score, PSNR, Accuracy, and F1-Score.
    """
    ious = []
    dices = []
    psnrs = []
    accuracys = []
    f1scores = []

    for image_file, mask_file in tqdm(zip(images_list, masks_list), total=len(images_list)):
        # Read an image and its corresponding mask
        image_tensor = read_image(image_file)
        mask_tensor = read_image(mask_file, mask=True)

        # Use the model to predict a mask with the new image
        prediction_mask = infer(image_tensor=image_tensor, model=model)

        # Flatten the arrays for metric computation
        actual = np.squeeze(mask_tensor.numpy()).astype(np.uint8).flatten()
        predicted = prediction_mask.astype(np.uint8).flatten()

        # Compute metrics
        ious.append(jaccard_score(actual, predicted, average="weighted"))
        dices.append(distance.dice(actual, predicted))
        psnrs.append(peak_signal_noise_ratio(actual, predicted))
        accuracys.append(accuracy_score(actual, predicted))
        f1scores.append(f1_score(actual, predicted, average="weighted"))

    # Return mean values for all metrics
    return [np.mean(ious),
            np.mean(dices),
            np.mean(psnrs),
            np.mean(accuracys),
            np.mean(f1scores)]

# Set the number of samples to evaluate
total_samples = 2016  # Adjust based on your test dataset size
# total_samples = len(test_images)  # Uncomment to use the full dataset

# Compute metrics
metrics = find_metrics(
    images_list=test_images[:total_samples],
    masks_list=test_masks[:total_samples],
    x_centers_list=test_acf_x_centers[:total_samples],
    y_centers_list=test_acf_y_centers[:total_samples],
    angles=test_angles[:total_samples],
    model=unet
)

# Print metrics
print("\n", "IoU:", metrics[0], "\nDice Score:", metrics[1], "\nPSNR:", metrics[2], "\nAccuracy:", metrics[3], "\nF1-Score:", metrics[4])